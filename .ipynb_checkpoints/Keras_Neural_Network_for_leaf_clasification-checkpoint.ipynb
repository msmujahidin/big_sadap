{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras_Neural_Network_for_leaf_clasification.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dq7ehdQ9aNC4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65
        },
        "outputId": "29fad7b8-e067-4caa-bc61-86650e9d0ce7"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "#TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "#Helper libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Helper libraries for label standarisation\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "#Helper libraries for fiture standaritaion\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYECJiE8vkto",
        "colab_type": "code",
        "outputId": "327f3230-99e0-425e-b4e7-3b7b43f06477",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv(\"DatasetGLCM.csv\")\n",
        "data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Citra', 'Class', 'energy90', 'contras90', 'homogenity90',\n",
              "       'correlation90'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 232
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipyQCYpLngV4",
        "colab_type": "text"
      },
      "source": [
        "#Load Leaf Dataset from Glcm feature\n",
        "Code di atas berfungsi untuk membaca dataset berbentuk csv yang merupakan data feature dari 7 kelas daun yang telah diekstraksi.\n",
        "\n",
        "Untuk membaca data di sini digunakan librari pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vm3boaEGaPdf",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2u50Q5HoHkH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = data[['energy90', 'contras90', 'homogenity90',\n",
        "       'correlation90']]\n",
        "\n",
        "#Standarissasi nilai homogenity\n",
        "sc = StandardScaler()\n",
        "x[['homogenity90']] = sc.fit_transform(x[['homogenity90']])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMPn0pupoLtv",
        "colab_type": "text"
      },
      "source": [
        "Code diatas berfungsi untuk mengambil data feature Daun dari file csv yang sudah dibaca sebelumnya dengan mengambil nomo kolom fiture secara spesifict. Hal ini diperlukan untuk memisahkan data input dengan data label untuk Klasifikasi nanti.\n",
        "\n",
        "Dalam data hasil ekstraksi fiture \"homogenity\" terdapat data feature yang bernilai lebih dari 1, maka diperlukan standarisasi nilai \"homogenity\" tersebut agar berada dibawah atau sama dengan 1.\n",
        "\n",
        "Hal ini diperlukan karena ANN sendiri hanya menerima input dibawah sama dengan 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "np664Pylv0G1",
        "colab_type": "code",
        "outputId": "03d062c2-2bc6-47d7-a0db-968f0e875a12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "y = data[[\"Class\"]]\n",
        "\n",
        "# Standarisasi label kelas\n",
        "ohe = OneHotEncoder()\n",
        "y = ohe.fit_transform(y).toarray()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXuPBOkCpjNe",
        "colab_type": "text"
      },
      "source": [
        "Code di atas berfungsi untuk mengambil label kelas dari masing masing data daun yang sudah diekstraksi yang ada pada file csv yang sudah dibaca sebelumnya.\n",
        "Dimana data kelas daun tersebut terdapat 7 kelas dengan dilabelkan 0,1,2,3,4,5, dan 6. Sebelum masuk ke dalam kelasifikasi label tersebut harus di encode terlebih dulu agar mepresentasikan 0 dan 1 sehingga nantinya dapat di kalkulasi dengan ANN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zs-aaZsvqLa-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUbAMi2KqMic",
        "colab_type": "text"
      },
      "source": [
        "## Split data for training and testing\n",
        "Code di atas berfungsi untuk memisahkan training dan testing untuk kebutuhan konowledge untuk ANN serta untuk testingnya. Untuk perbandingannya sendiri di sini menggunakan perbandinga 90:10. Untuk masing masing data training dan testingnya."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmIVyxohuYD4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Dense(16, input_dim=4, activation=\"relu\"))\n",
        "model.add(keras.layers.Dense(12, activation=\"relu\"))\n",
        "model.add(keras.layers.Dense(7, activation=\"softmax\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJ5OcMjZqqU8",
        "colab_type": "text"
      },
      "source": [
        "#Create ANN model\n",
        "Code diatas berfungsi untuk membuat model ANN untuk klasifikasi. Model ANN yang dibuat disini harus sesuai dengan kebutuhan sesuai data yang akan diklasifikasi. \n",
        "\n",
        "Model ANN untuk data yang akan diklasifikasi disini yaitu ANN dengan 4 layer input, dan 2 hiden layer masing masing berjumlah 16 dan 12, serta 7 layer ouput. \n",
        "\n",
        "Untuk Activation function pada  masing masing hiden layer menggunakan \"relu\" sedangkan untuk output layer menggunakan \"softmax\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LY4_tN2mubC7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDU358grrbqN",
        "colab_type": "text"
      },
      "source": [
        "Code di atas berfungsi untuk mengatur untuk model ANN sebelumnya. Dimana yang di atur disini adalah fungsi optimasi yang digunakan, loss function yang digunakan, serta mengatur agar saat training berjalan record akurasi serta waktu belajar per epoch dapat diperlihatkan.\n",
        "\n",
        "Untuk optimizer digunakan fungsi \"adam\"\n",
        "Untuk loss function digunakan \"categorical_crossentropy\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGX1tzcEuesx",
        "colab_type": "code",
        "outputId": "b7065a16-e2a0-47ed-f461-d08f10ec14cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "history = model.fit(np.array(x_train), y_train, epochs=10, batch_size=35)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 257 samples\n",
            "Epoch 1/10\n",
            "257/257 [==============================] - 0s 71us/sample - loss: 0.2904 - acc: 0.8833\n",
            "Epoch 2/10\n",
            "257/257 [==============================] - 0s 73us/sample - loss: 0.2879 - acc: 0.8833\n",
            "Epoch 3/10\n",
            "257/257 [==============================] - 0s 68us/sample - loss: 0.2879 - acc: 0.8949\n",
            "Epoch 4/10\n",
            "257/257 [==============================] - 0s 75us/sample - loss: 0.2900 - acc: 0.8988\n",
            "Epoch 5/10\n",
            "257/257 [==============================] - 0s 63us/sample - loss: 0.2882 - acc: 0.8872\n",
            "Epoch 6/10\n",
            "257/257 [==============================] - 0s 64us/sample - loss: 0.2899 - acc: 0.8833\n",
            "Epoch 7/10\n",
            "257/257 [==============================] - 0s 76us/sample - loss: 0.2858 - acc: 0.8833\n",
            "Epoch 8/10\n",
            "257/257 [==============================] - 0s 71us/sample - loss: 0.2891 - acc: 0.8794\n",
            "Epoch 9/10\n",
            "257/257 [==============================] - 0s 64us/sample - loss: 0.2879 - acc: 0.8911\n",
            "Epoch 10/10\n",
            "257/257 [==============================] - 0s 73us/sample - loss: 0.2864 - acc: 0.8833\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3LqTTY4sPYP",
        "colab_type": "text"
      },
      "source": [
        "Code di atas berfungsi untuk melakukan fiting atau pembelajaran pada model ANN yang telah dibuat, dimana pembelajaran di sini dilakukan sebanyak 10 epoch dengan batch size sebesar 35. Maknanya salam 1 kali epoch model ANN belajar/mengulang selama 35 kali."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQPWt-WgbbEQ",
        "colab_type": "code",
        "outputId": "91d4ee1b-efc0-4a68-d325-b64e2b4cb2da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "test_loss, test_acc = model.evaluate(np.array(x_test),  np.array(y_test), verbose=2)\n",
        "\n",
        "print('\\nTest accuracy:', test_acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "29/29 - 0s - loss: 0.3352 - acc: 0.8966\n",
            "\n",
            "Test accuracy: 0.8965517\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGvTTS9Xsl3J",
        "colab_type": "text"
      },
      "source": [
        "Code di atas berfungsi untuk melihat akurasi dari akurasi dari model ANN yang telah dibuat untuk melakukan prediksi. Di sini data yang digunakan adalah data testing yang sudah di dapat sebelumnya.\n",
        "\n",
        "Dimana yang dapat kita lihat dari ouput code di atas yaitu besar akurasi testingnya sebesar sekitar 89 %, dengan nilai loss sekkitar 30%."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCTHuTCjzqDG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = model.predict(np.array(x_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OH2MV-4VzrSi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict_value = []\n",
        "expected_value = []\n",
        "\n",
        "for i in range(len(predictions)-1):\n",
        "  predict_value.append(np.argmax(predictions[0]))\n",
        "  expected_value.append(np.argmax(y_test[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hmv9aRsZw65k",
        "colab_type": "code",
        "outputId": "c5edcac2-b76f-42d6-dd45-08e30497dfcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.metrics import r2_score\n",
        "r2_score(np.array(expected_value), np.array(predict_value))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 289
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zx5_8TFHxln6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}